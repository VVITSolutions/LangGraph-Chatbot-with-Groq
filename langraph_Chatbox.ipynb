{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPUWO4UtXLdCJPPeHWHzM1b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["LangGraph Chatbot with Groq (Simple Chatbox)"],"metadata":{"id":"rq1uweupBLqU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAVutSWUveqR"},"outputs":[],"source":["# Install required packages (run once)\n","!pip install langgraph langsmith\n","!pip install langchain langchain_groq langchain_community"]},{"cell_type":"code","source":["# Retrieve API keys securely from Colab secrets\n","from google.colab import userdata\n","groq_api_key=userdata.get('Grog_Api_Key')\n","langsmith=userdata.get('langsmith_api_key')\n","print(groq_api_key)\n","print(langsmith)"],"metadata":{"id":"sG5kgOP7x2By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set environment variables for LangSmith (we disable tracing to avoid warnings)\n","import os\n","os.environ[\"langsmith_api_key\"] = langsmith\n","os.environ[\"LANGCHAIN_TRACING_V2\"]=\"false\"\n","os.environ[\"LANGCHAIN_PROJECT\"]=\"TestLanggraph\""],"metadata":{"id":"vPntJYni2DQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the Groq LLM wrapper from LangChain\n","from langchain_groq import ChatGroq"],"metadata":{"id":"jK2PjCYK2sRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize the LLM using Groq's hosted model (openai/gpt-oss-120b is a large open-source model via Groq)\n","llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"openai/gpt-oss-120b\")\n","llm"],"metadata":{"id":"iO9ZkT2V2xct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Start Building Chatbot Using Langgraph"],"metadata":{"id":"RDc7RviFCVKB"}},{"cell_type":"code","source":["## Start Building Chatbot Using LangGraph\n","from typing import Annotated\n","from typing_extensions import TypedDict\n","# Core LangGraph imports\n","from langgraph.graph import StateGraph,START,END\n","from langgraph.graph.message import add_messages"],"metadata":{"id":"TIzpH6w63ls1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the state structure for the graph\n","# The state holds a list of messages, and add_messages ensures new messages are appended\n","class State(TypedDict):\n","  # Messages have the type \"list\". The `add_messages` function\n","    # in the annotation defines how this state key should be updated\n","    # (in this case, it appends messages to the list, rather than overwriting them)\n","  messages:Annotated[list,add_messages]\n","\n","# Create a StateGraph builder instance\n","graph_builder=StateGraph(State)\n"],"metadata":{"id":"dVzn-8rrC6-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_builder"],"metadata":{"id":"q8xjN1Pp4n4N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the chatbot node: takes current state, calls LLM, returns new message\n","def chatbot(state:State):\n","  return {\"messages\":llm.invoke(state['messages'])}"],"metadata":{"id":"bSjc_B0S4zc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Add the chatbot node to the graph\n","graph_builder.add_node(\"chatbot\",chatbot)"],"metadata":{"id":"O7WDIw6g48Bx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the flow: START → chatbot → END\n","graph_builder.add_edge(START,\"chatbot\")\n","graph_builder.add_edge(\"chatbot\",END)"],"metadata":{"id":"6M6xh9UV5QWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the graph into an executable app\n","graph=graph_builder.compile()"],"metadata":{"id":"bL6ftV-m5VSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optional: Visualize the graph structure (requires mermaid support)\n","from IPython.display import Image, display\n","try:\n","  display(Image(graph.get_graph().draw_mermaid_png()))\n","except Exception:\n","  pass"],"metadata":{"id":"BqLMGai05aSy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Simple synchronous chat loop using graph.stream()\n","while True:\n","    user_input = input(\"User: \")\n","    if user_input.lower() in [\"quit\", \"q\"]:\n","        print(\"Good Bye\")\n","        break\n","\n","    print(\"Assistant:\", end=\" \", flush=True)\n","\n","    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n","        for node_name, node_state in event.items():\n","            if \"messages\" in node_state:\n","                msg = node_state[\"messages\"]\n","                # Handle both list and single message\n","                if isinstance(msg, list):\n","                    msg = msg[-1]\n","                if hasattr(msg, \"content\"):\n","                    print(msg.content, end=\"\", flush=True)\n","\n","    print(\"\\n\" + \"-\" * 50)"],"metadata":{"id":"GKcYM1065t-Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Astream Events (async) - For real-time token streaming"],"metadata":{"id":"_gdEtY0D94E2"}},{"cell_type":"code","source":["import nest_asyncio\n","nest_asyncio.apply()\n","\n","import asyncio\n","\n","async def chat_loop():\n","    while True:\n","        user_input = input(\"User: \")\n","        if user_input.lower() in [\"quit\", \"q\"]:\n","            print(\"Good Bye\")\n","            break\n","\n","        print(\"Assistant:\", end=\" \", flush=True)\n","\n","        async for event in graph.astream_events(\n","            input={\"messages\": [(\"user\", user_input)]},\n","            version=\"v2\"\n","        ):\n","            kind = event[\"event\"]\n","            if kind == \"on_chat_model_stream\":\n","                chunk = event[\"data\"][\"chunk\"]\n","                if chunk.content:\n","                    print(chunk.content, end=\"\", flush=True)\n","\n","        print(\"\\n\" + \"-\" * 50)\n","\n","\n","asyncio.run(chat_loop())"],"metadata":{"id":"Igmo5yYq9-Om"},"execution_count":null,"outputs":[]}]}